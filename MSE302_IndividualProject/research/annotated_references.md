|  **#** | **Source**                                                                                                                                                                       | **Type**                          | **Summary**                                                                                                                                  | **Key Insights**                                                                                                              | **Relevance to Project**                                                        | **Quality Assessment**                                                                                                                                         |
| :----: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|  **1** | **Fitzpatrick, K. K., Darcy, A., & Vierhile, M.** (2017). *Delivering Cognitive Behavioral Therapy to Young Adults Using a Conversational Agent (Woebot)*. *JMIR Mental Health.* | Peer-reviewed academic study      | RCT tested *Woebot*, a CBT chatbot, on young adults with depression/anxiety. Participants showed **20–25% symptom reduction** after 2 weeks. | - Chatbots can deliver CBT effectively.<br>- Demonstrates measurable impact and engagement through daily micro-conversations. | Foundational evidence that **AI-driven CBT tools benefit student populations**. | **Strengths:** Rigorous RCT, quantitative data.<br>**Limitations:** Small sample (N=70), short duration.<br>**Credibility:** Peer-reviewed, reputable journal. |
|  **2** | **Inkster, B., & Montague, E.** (2022). *Evaluating the Therapeutic Alliance with a Free-Text CBT Agent (Wysa).* *Frontiers in Digital Health.*                                  | Academic research article         | Examines user empathy and alliance with *Wysa*. Users valued 24/7 access but noted limited emotional understanding.                          | - Empathy drives sustained use.<br>- Highlights need for emotional authenticity in automation.                                | Informs design of **context-aware AI life coach** for students.                 | **Strengths:** User interviews; emotional insights.<br>**Limitations:** Self-selected, short-term.<br>**Credibility:** Leading open-access journal.            |
|  **3** | **HEQCO.** (2024). *Supporting Student Mental Health in Ontario: Exploring Best Practices.*                                                                                      | Government report                 | Reviews wellness initiatives across Ontario universities. Finds **4–6 week counselling waits** and **1:1900 staff ratio**.                   | - Quantifies service constraints.<br>- Recommends hybrid outreach and proactive care.                                         | Defines **systemic accessibility gap** the AI coach will supplement.            | **Strengths:** Government-funded, data-driven.<br>**Limitations:** Ontario-only.<br>**Credibility:** Recognized provincial agency.                             |
|  **4** | **Inkster, B., et al.** (2023). *An Overview of Chatbot-Based Mobile Mental-Health Apps.* *Frontiers in Digital Health.*                                                         | Systematic review                 | Surveys chatbots like *Woebot*, *Wysa*, *Tess*. Evaluates validation, ethics, and user engagement.                                           | - Global rise in AI wellness tools.<br>- Most lack validation or crisis features.<br>- Advocates clinical oversight.          | Identifies **gaps in ethics, safety, and oversight**.                           | **Strengths:** Comprehensive review.<br>**Limitations:** Rapidly evolving field.<br>**Credibility:** Peer-reviewed systematic analysis.                        |
|  **5** | **Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S.** (2021). *On the Dangers of Stochastic Parrots.* *ACM FAccT Conference.*                                       | Academic ethics paper             | Critiques large language models for bias, opacity, and misuse in healthcare contexts.                                                        | - Warns of unregulated bias.<br>- Calls for transparency and governance.                                                      | Informs **ethical safeguards** for AI life coach.                               | **Strengths:** Seminal, widely cited.<br>**Limitations:** Theoretical.<br>**Credibility:** Top-tier AI ethics venue.                                           |
|  **6** | **U.S. News & World Report.** (2024). *Mental Health on College Campuses: Challenges and Solutions.*                                                                             | Investigative journalism          | Reviews U.S. college mental-health crisis; rising anxiety, stress, and counselling demand post-pandemic.                                     | - National increase in student cases.<br>- Supports hybrid human–AI approaches.                                               | **Cross-border validation** of Canadian trends.                                 | **Strengths:** Multi-campus data, experts.<br>**Limitations:** Journalistic, non-peer-reviewed.<br>**Credibility:** Reputable media source.                    |
|  **7** | **National Alliance on Mental Illness (NAMI).** (2024). *Mental Health in College: Understanding and Supporting Young Adults.*                                                   | Nonprofit educational report      | Discusses stigma, barriers, and early intervention strategies for college students.                                                          | - Stigma deters help-seeking.<br>- Promotes peer & digital supports.<br>- Encourages early intervention.                      | Supports a **stigma-free, 24/7 AI life coach** model.                           | **Strengths:** Evidence-based guidance.<br>**Limitations:** U.S.-centric, limited data.<br>**Credibility:** High—national nonprofit.                           |
|  **8** | **APA Services.** (2023). *AI Chatbots and the Future of Therapy.*                                                                                                               | Professional commentary           | Discusses ethical integration of chatbots in therapy. Stresses **augmentation, not replacement** of human therapists.                        | - Recommends best practices for ethical use.<br>- Advocates human oversight.                                                  | Supports **AI as complement, not substitute** for counselling.                  | **Strengths:** Written by clinical experts.<br>**Limitations:** Conceptual.<br>**Credibility:** High—APA publication.                                          |
|  **9** | **Stanford HAI.** (2024). *Exploring the Dangers of AI in Mental-Health Care.*                                                                                                   | Institutional research commentary | Examines AI risks like data misuse, bias, and dependency in therapeutic contexts.                                                            | - Calls for regulation and ethical audits.<br>- Frames AI as assistive.                                                       | Reinforces need for **ethical audits and transparency**.                        | **Strengths:** University-backed; policy-linked.<br>**Limitations:** Non-peer-reviewed.<br>**Credibility:** High—Stanford AI ethics institute.                 |
| **10** | **BitCot Technologies.** (2024). *AI Chatbots for Mental-Health Support Projects.*                                                                                               | Industry case study               | Summarizes real-world chatbot projects with emotion-recognition and journaling.                                                              | - Shows feasibility and scalability.<br>- Highlights privacy and trust factors.                                               | Validates **engineering feasibility** for implementation.                       | **Strengths:** Real-world examples.<br>**Limitations:** Marketing tone.<br>**Credibility:** Moderate—industry source.                                          |
